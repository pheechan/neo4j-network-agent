import os
from dotenv import load_dotenv
from typing import List
import requests
import streamlit as st

try:
	from neo4j import GraphDatabase
except Exception:
	GraphDatabase = None

import os
from datetime import datetime
from typing import List, Dict

import streamlit as st
import requests
from dotenv import load_dotenv

try:
	from neo4j import GraphDatabase
except Exception:
	GraphDatabase = None

load_dotenv()

# Read from Streamlit secrets (cloud) or environment variables (local)
def get_config(key, default=""):
	"""Get config from st.secrets (Streamlit Cloud) or os.getenv (local)"""
	try:
		return st.secrets.get(key, os.getenv(key, default))
	except:
		return os.getenv(key, default)

# Configuration (from .env or Streamlit secrets)
NEO4J_URI = get_config("NEO4J_URI", "bolt://localhost:7687")
NEO4J_USER = get_config("NEO4J_USERNAME", "neo4j")
NEO4J_PWD = get_config("NEO4J_PASSWORD", "")
NEO4J_DB = get_config("NEO4J_DATABASE", "neo4j")

OPENROUTER_API_KEY = get_config("OPENROUTER_API_KEY") or get_config("OPENAI_API_KEY")
OPENROUTER_API_BASE = get_config("OPENROUTER_API_BASE", get_config("OPENAI_API_BASE", "https://api.openrouter.ai"))
OPENROUTER_MODEL = get_config("OPENROUTER_MODEL", "deepseek/deepseek-chat")

# Vector/RAG configuration (optional, used by KG/VectorRAG.query_vector_rag)
# Use person_vector_index as default since Person is likely the most queried label
VECTOR_INDEX_NAME = get_config("VECTOR_INDEX_NAME", "person_vector_index")
VECTOR_NODE_LABEL = get_config("VECTOR_NODE_LABEL", "Person")
# Use embedding_text which contains the formatted text used to generate embeddings
VECTOR_SOURCE_PROPERTY = get_config("VECTOR_SOURCE_PROPERTY", "embedding_text")
VECTOR_EMBEDDING_PROPERTY = get_config("VECTOR_EMBEDDING_PROPERTY", "embedding")
VECTOR_TOP_K = int(get_config("VECTOR_TOP_K", "5"))

# Try to import direct vector search (bypasses LangChain's broken text extraction)
try:
	from KG.VectorSearchDirect import query_vector_search_direct, query_multiple_vector_indexes, query_with_relationships
	VECTOR_SEARCH_AVAILABLE = True
except Exception as e:
	query_vector_search_direct = None
	query_multiple_vector_indexes = None
	query_with_relationships = None
	VECTOR_SEARCH_AVAILABLE = False
	print(f"Direct vector search not available: {e}")

# Try to import HuggingFace embeddings for generating embeddings
try:
	from langchain_huggingface import HuggingFaceEmbeddings
	EMBEDDINGS_AVAILABLE = True
except Exception as e:
	HuggingFaceEmbeddings = None
	EMBEDDINGS_AVAILABLE = False
	print(f"HuggingFace embeddings not available: {e}")


def get_driver():
	if GraphDatabase is None:
		raise RuntimeError("neo4j driver missing. Install with: python -m pip install neo4j")
	return GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PWD))


@st.cache_resource
def get_embeddings_model():
	"""Load HuggingFace embeddings model (cached)"""
	if not EMBEDDINGS_AVAILABLE:
		return None
	return HuggingFaceEmbeddings(
		model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
	)


def generate_embeddings_for_nodes(driver, limit=50):
	"""
	Generate embeddings for nodes that don't have them yet.
	Returns (success_count, total_processed, error_messages)
	"""
	embeddings_model = get_embeddings_model()
	if embeddings_model is None:
		return 0, 0, ["HuggingFace embeddings not available"]
	
	errors = []
	success_count = 0
	total_processed = 0
	
	# Get all labels
	with driver.session(database=NEO4J_DB) as session:
		result = session.run("CALL db.labels()")
		labels = [record["label"] for record in result]
	
	# Process each label
	for label in labels:
		with driver.session(database=NEO4J_DB) as session:
			# Find nodes without embeddings OR without embedding_text (need to regenerate)
			query = f"""
			MATCH (n:`{label}`)
			WHERE n.embedding IS NULL OR n.embedding_text IS NULL
			RETURN id(n) as nodeId, properties(n) as props
			LIMIT $limit
			"""
			result = session.run(query, limit=limit)
			nodes = list(result)
			
			for record in nodes:
				total_processed += 1
				node_id = record["nodeId"]
				props = record["props"]
				
				# Create text from properties (include all string and number properties)
				text_parts = []
				for key, value in props.items():
					if key not in ["embedding", "embedding_text"] and value is not None:
						if isinstance(value, str):
							text_parts.append(f"{key}: {value}")
						elif isinstance(value, (int, float)):
							text_parts.append(f"{key}: {value}")
				
				if not text_parts:
					errors.append(f"Skipped {label} node {node_id}: No text properties found (keys: {list(props.keys())})")
					continue
				
				text = " | ".join(text_parts)
				
				try:
					# Generate embedding
					embedding = embeddings_model.embed_query(text)
					
					# Store embedding
					update_query = f"""
					MATCH (n:`{label}`)
					WHERE id(n) = $nodeId
					SET n.embedding = $embedding,
					    n.embedding_text = $text
					"""
					session.run(update_query, nodeId=node_id, embedding=embedding, text=text)
					success_count += 1
				except Exception as e:
					errors.append(f"Error on {label} node {node_id}: {str(e)[:100]}")
	
	return success_count, total_processed, errors


def search_nodes(driver, question: str, limit: int = 6) -> List[dict]:
	"""
	Search for nodes containing the question text in ANY string property.
	Supports partial matching - splits query into words and searches for each.
	"""
	# Split query into words (works for both Thai and English)
	words = [w.strip() for w in question.split() if len(w.strip()) > 1]
	
	# Build query that searches for ANY word in the query
	# This helps with Thai names that might be stored differently
	q = """
	MATCH (n)
	WHERE any(prop IN keys(n) WHERE 
		prop <> 'embedding' AND 
		prop <> 'embedding_text' AND
		n[prop] IS NOT NULL AND 
		valueType(n[prop]) = 'STRING' AND
		any(word IN $words WHERE toLower(n[prop]) CONTAINS toLower(word))
	)
	RETURN n, labels(n) as node_labels
	LIMIT $limit
	"""
	out = []
	with driver.session(database=NEO4J_DB) as session:
		# If no valid words, fall back to original query
		if not words:
			words = [question]
		res = session.run(q, words=words, limit=limit)
		for r in res:
			node = r.get("n")
			try:
				props = dict(node)
				# Add labels to the props dict for debugging
				props["__labels__"] = r.get("node_labels", [])
			except Exception:
				props = {}
			out.append(props)
	return out


def build_context(nodes: List[dict]) -> str:
	"""
	Build context from node properties.
	Handles both English and Thai property names, plus custom "Stelligence" field.
	NOW also includes relationship information (WORKS_AS, etc.).
	"""
	if not nodes:
		return ""
	pieces = []
	for i, n in enumerate(nodes, 1):
		# Try common property names (English + Thai + custom "Stelligence")
		name = (n.get("name") or 
		        n.get("title") or 
		        n.get("label") or 
		        n.get("Stelligence") or 
		        n.get("à¸Šà¸·à¹ˆà¸­-à¸™à¸²à¸¡à¸ªà¸à¸¸à¸¥") or  # Thai: Full Name
		        n.get("à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡") or       # Thai: Position
		        n.get("à¸«à¸™à¹ˆà¸§à¸¢à¸‡à¸²à¸™") or      # Thai: Agency
		        n.get("à¸à¸£à¸°à¸—à¸£à¸§à¸‡") or       # Thai: Ministry
		        n.get("id") or 
		        f"node_{i}")
		
		# Try common property names for content/description (English + Thai)
		text_props = []
		content_keys = [
			"text", "description", "content", "summary", "value",
			"Stelligence",
			"à¸Šà¸·à¹ˆà¸­-à¸™à¸²à¸¡à¸ªà¸à¸¸à¸¥",    # Thai: Full Name
			"à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡",         # Thai: Position
			"à¸«à¸™à¹ˆà¸§à¸¢à¸‡à¸²à¸™",        # Thai: Agency
			"à¸à¸£à¸°à¸—à¸£à¸§à¸‡",         # Thai: Ministry
			"Connect by",
			"Remark",
			"Associate",
			"à¸Šà¸·à¹ˆà¸­à¹€à¸¥à¹ˆà¸™",        # Thai: Nickname
			"Level"
		]
		for key in content_keys:
			if key in n and n[key]:
				text_props.append(f"{key}: {n[key]}")
		
		# If no common text properties, include all string values (excluding labels, IDs, and embeddings)
		if not text_props:
			for key, val in n.items():
				if key not in ["__labels__", "id", "embedding", "embedding_text", "__relationships__", "__score__"] and val and isinstance(val, str):
					text_props.append(f"{key}: {val}")
		
		text = " | ".join(text_props) if text_props else ""
		
		# Include labels if available
		labels = n.get("__labels__", [])
		label_str = f" ({', '.join(labels)})" if labels else ""
		
		# Add relationship information if available
		relationships = n.get("__relationships__", [])
		rel_info = []
		if relationships and isinstance(relationships, list):
			for rel in relationships:
				if rel and isinstance(rel, dict):
					rel_type = rel.get("type", "")
					direction = rel.get("direction", "")
					connected_node = rel.get("node", {})
					connected_labels = rel.get("labels", [])
					
					# Skip if no relationship type or connected node
					if not rel_type or not connected_node:
						continue
					
					# Get meaningful info from connected node
					connected_name = None
					for key in ["Stelligence", "à¸Šà¸·à¹ˆà¸­-à¸™à¸²à¸¡à¸ªà¸à¸¸à¸¥", "à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡", "à¸«à¸™à¹ˆà¸§à¸¢à¸‡à¸²à¸™", "name", "title"]:
						if connected_node and key in connected_node and connected_node[key]:
							connected_name = connected_node[key]
							break
					
					if connected_name:
						label_str_conn = f" ({', '.join(connected_labels)})" if connected_labels else ""
						if direction == "outgoing":
							rel_info.append(f"{rel_type} â†’ {connected_name}{label_str_conn}")
						else:
							rel_info.append(f"â† {rel_type} â† {connected_name}{label_str_conn}")
		
		# Combine node info with relationships
		node_str = f"{name}{label_str}: {text}"
		if rel_info:
			node_str += "\n  Relationships: " + ", ".join(rel_info)
		
		pieces.append(node_str)
	return "\n\n".join(pieces)


### Local fallback (in-memory) â€” used when Neo4j / vector retrieval are unavailable
FALLBACK_DOCS = [
	{"name": "Waterloo", "text": "The Battle of Waterloo occurred in 1815 near Waterloo in present-day Belgium."},
	{"name": "Napoleon", "text": "Napoleon Bonaparte was a French statesman and military leader who rose to prominence during the French Revolution."},
	{"name": "Talleyrand", "text": "Charles Maurice de Talleyrand-PÃ©rigord was a French diplomat who served under several regimes."},
]


def local_search(question: str, limit: int = 3) -> List[dict]:
	"""Very small keyword-based fallback search over FALLBACK_DOCS.

	This ensures the Streamlit UI remains responsive even when external services are unavailable.
	"""
	q = (question or "").lower()
	results = []
	for doc in FALLBACK_DOCS:
		score = 0
		text = (doc.get("text") or "").lower()
		name = (doc.get("name") or "").lower()
		if any(w in text for w in q.split() if len(w) > 2):
			score += 2
		if any(w in name for w in q.split() if len(w) > 2):
			score += 3
		# small heuristic: longer question -> prefer text matches
		if q and q in text:
			score += 5
		if score > 0:
			results.append((score, doc))
	# sort by score desc and return only the doc dicts
	results.sort(key=lambda x: x[0], reverse=True)
	return [r[1] for r in results[:limit]]


def ask_openrouter_requests(prompt: str, model: str = OPENROUTER_MODEL, max_tokens: int = 512) -> str:
	if not OPENROUTER_API_KEY:
		return "OpenRouter API key not set (OPENROUTER_API_KEY or OPENAI_API_KEY)"
	
	# Handle both base URL formats:
	# - https://api.openrouter.ai (needs /v1/chat/completions)
	# - https://openrouter.ai/api/v1 (needs /chat/completions)
	base = OPENROUTER_API_BASE.rstrip('/')
	if base.endswith('/v1'):
		# Already has /v1, just add /chat/completions
		url = f"{base}/chat/completions"
	else:
		# Need to add /v1/chat/completions
		url = f"{base}/v1/chat/completions"
	
	headers = {
		"Authorization": f"Bearer {OPENROUTER_API_KEY}",
		"Content-Type": "application/json",
	}
	payload = {
		"model": model,
		"messages": [{"role": "user", "content": prompt}],
		"temperature": 0.2,
		"max_tokens": max_tokens,
	}
	try:
		r = requests.post(url, headers=headers, json=payload, timeout=60)
		r.raise_for_status()
		j = r.json()
		return j["choices"][0]["message"]["content"].strip()
	except Exception as e:
		return f"OpenRouter request failed: {type(e).__name__} {e}"


## Streamlit chat UI with ChatGPT-like design
st.set_page_config(
	page_title="Neo4j Chat Agent", 
	layout="centered",  # Changed from "wide" to "centered" for ChatGPT-like feel
	page_icon="ğŸ¤–",
	initial_sidebar_state="collapsed"  # Start with sidebar hidden
)

# Custom CSS for ChatGPT-like styling with dark sidebar
st.markdown("""
<style>
	/* Hide Streamlit branding */
	#MainMenu {visibility: hidden;}
	footer {visibility: hidden;}
	
	/* Adjust spacing for cleaner look */
	.block-container {
		padding-top: 2rem;
		padding-bottom: 2rem;
	}
	
	/* Style chat messages */
	.stChatMessage {
		padding: 1rem;
		border-radius: 0.5rem;
	}
	
	/* Dark sidebar styling */
	[data-testid="stSidebar"] {
		background-color: #202123;
	}
	
	[data-testid="stSidebar"] * {
		color: #ececf1 !important;
	}
	
	[data-testid="stSidebar"] button {
		background-color: #2d2d30;
		border: 1px solid #4d4d4f;
		color: #ececf1 !important;
	}
	
	[data-testid="stSidebar"] button:hover {
		background-color: #3d3d40;
		border-color: #6d6d6f;
	}
	
	[data-testid="stSidebar"] hr {
		border-color: #4d4d4f;
	}
	
	/* Chat input styling */
	.stChatInput {
		border-radius: 1.5rem;
	}
</style>
""", unsafe_allow_html=True)

if "threads" not in st.session_state:
	# threads: dict[thread_id] -> {"title": str, "messages": [ {role,content,time} ]}
	st.session_state.threads = {1: {"title": "Default", "messages": []}}
	st.session_state.current_thread = 1
	st.session_state.thread_counter = 1


def new_thread(title: str = None):
	st.session_state.thread_counter += 1
	tid = st.session_state.thread_counter
	st.session_state.threads[tid] = {"title": title or f"Thread {tid}", "messages": []}
	st.session_state.current_thread = tid


def clear_current_thread():
	tid = st.session_state.current_thread
	st.session_state.threads[tid]["messages"] = []


with st.sidebar:
	st.markdown("### ğŸ’¬ Neo4j Chat Agent")
	st.markdown("---")
	
	# Thread management
	st.markdown("**Conversations**")
	for tid, meta in list(st.session_state.threads.items()):
		label = f"ğŸ’¬ {meta['title']}"
		if st.button(label, key=f"thread-{tid}", use_container_width=True):
			st.session_state.current_thread = tid

	col_a, col_b = st.columns(2)
	with col_a:
		if st.button("â• New", key="new_thread", use_container_width=True):
			new_thread()
			st.rerun()
	with col_b:
		if st.button("ğŸ—‘ï¸ Clear", key="clear_thread", use_container_width=True):
			clear_current_thread()
			st.rerun()
	
	st.markdown("---")
	st.markdown("**Settings**")
	with st.expander("ğŸ”§ Configuration"):
		st.caption(f"**Model:** {OPENROUTER_MODEL}")
		st.caption(f"**Neo4j:** {NEO4J_DB}")
		st.caption(f"**URI:** {NEO4J_URI[:30]}...")
	
	st.markdown("---")
	st.markdown("**ğŸ”§ Admin Tools**")
	
	if EMBEDDINGS_AVAILABLE:
		if st.button("âš¡ Generate Embeddings", key="gen_embeddings", use_container_width=True, help="Generate embeddings for nodes without them"):
			with st.spinner("Generating embeddings..."):
				try:
					driver = get_driver()
					success, total, errors = generate_embeddings_for_nodes(driver, limit=100)
					driver.close()
					
					if success > 0:
						st.success(f"âœ… Generated {success} embeddings (processed {total} nodes)")
					else:
						st.warning(f"âš ï¸ No embeddings generated (processed {total} nodes)")
					
					if errors:
						with st.expander("âš ï¸ Errors"):
							for err in errors[:10]:
								st.caption(err)
				except Exception as e:
					st.error(f"Error: {e}")
	else:
		st.caption("âš ï¸ HuggingFace embeddings not installed")
		st.caption("Run: `pip install langchain-huggingface sentence-transformers`")
	
	st.markdown("---")
	st.markdown("**ğŸ” Database Debug**")
	
	if st.button("ğŸ“Š Check Database Status", key="check_db", use_container_width=True):
		with st.spinner("Checking database..."):
			try:
				driver = get_driver()
				with driver.session(database=NEO4J_DB) as session:
					# Check for vector indexes
					st.markdown("**Vector Indexes:**")
					result = session.run("SHOW INDEXES WHERE type = 'VECTOR'")
					indexes = list(result)
					if indexes:
						for idx in indexes:
							st.caption(f"âœ… {idx.get('name')} - {idx.get('labelsOrTypes')}")
					else:
						st.warning("âš ï¸ No vector indexes found!")
						st.caption("Create indexes in Neo4j Browser:")
						st.code("""CREATE VECTOR INDEX person_vector_index IF NOT EXISTS
FOR (n:Person) ON n.embedding
OPTIONS {indexConfig: {
  `vector.dimensions`: 384,
  `vector.similarity_function`: 'cosine'
}};""", language="cypher")
					
					# Check for nodes with embeddings
					st.markdown("**Nodes with Embeddings:**")
					result = session.run("""
						MATCH (n)
						WHERE n.embedding IS NOT NULL
						RETURN labels(n)[0] as label, count(n) as count
						ORDER BY count DESC
						LIMIT 10
					""")
					nodes_with_emb = list(result)
					if nodes_with_emb:
						for record in nodes_with_emb:
							st.caption(f"âœ… {record['label']}: {record['count']} nodes")
					else:
						st.warning("âš ï¸ No nodes have embeddings! Click 'Generate Embeddings' above.")
					
					# Check for nodes with embedding_text
					st.markdown("**Nodes with embedding_text:**")
					result = session.run("""
						MATCH (n)
						WHERE n.embedding_text IS NOT NULL
						RETURN labels(n)[0] as label, count(n) as count
						ORDER BY count DESC
						LIMIT 10
					""")
					nodes_with_text = list(result)
					if nodes_with_text:
						for record in nodes_with_text:
							st.caption(f"ğŸ“ {record['label']}: {record['count']} nodes")
					else:
						st.warning("âš ï¸ No nodes have embedding_text! Click 'Generate Embeddings' to add it.")
					
					# Check for Santisook label specifically
					st.markdown("**Santisook Label Nodes:**")
					result = session.run("""
						MATCH (n:Santisook)
						RETURN n.Stelligence as stelligence,
						       n.embedding IS NOT NULL as has_embedding,
						       n.embedding_text as embedding_text,
						       keys(n) as properties
						LIMIT 3
					""")
					santisook_label = list(result)
					if santisook_label:
						for record in santisook_label:
							emb = "âœ…" if record['has_embedding'] else "âŒ"
							txt = "ğŸ“" if record['embedding_text'] else "âŒ"
							props = ', '.join([p for p in record['properties'] if p not in ['embedding', 'embedding_text']])
							st.caption(f"{emb} Emb | {txt} Text | Stelligence: {record['stelligence']} | Props: {props}")
					else:
						st.caption("No Santisook label nodes found")
					
					# Test Search
					st.markdown("**Test Search (Santisook):**")
					result = session.run("""
						MATCH (n)
						WHERE any(prop IN keys(n) WHERE 
							prop <> 'embedding' AND 
							prop <> 'embedding_text' AND
							n[prop] IS NOT NULL AND 
							(
								(valueType(n[prop]) = 'STRING' AND toLower(n[prop]) CONTAINS 'santisook') OR
								(valueType(n[prop]) = 'INTEGER' AND toString(n[prop]) CONTAINS 'santisook')
							)
						)
						RETURN labels(n) as labels, n.Stelligence as stelligence, 
						       n.`à¸Šà¸·à¹ˆà¸­-à¸™à¸²à¸¡à¸ªà¸à¸¸à¸¥` as name, n.embedding IS NOT NULL as has_embedding,
						       n.embedding_text IS NOT NULL as has_text
						LIMIT 3
					""")
					santisook_nodes = list(result)
					if santisook_nodes:
						for record in santisook_nodes:
							name_val = record['stelligence'] or record['name'] or "N/A"
							emb_status = "âœ…" if record['has_embedding'] else "âŒ"
							text_status = "ğŸ“" if record.get('has_text') else "âŒ"
							st.caption(f"{emb_status} Embedding | {text_status} Text | {record['labels']} - {name_val}")
					else:
						st.warning("âš ï¸ No nodes found with 'Santisook'!")
				
				driver.close()
			except Exception as e:
				st.error(f"Error: {str(e)[:200]}")


def render_messages(messages: List[Dict]):
	"""Render messages in ChatGPT style"""
	for m in messages:
		role = m.get("role")
		content = m.get("content")
		if role == "user":
			with st.chat_message("user", avatar="ğŸ‘¤"):
				st.markdown(content)
		else:
			with st.chat_message("assistant", avatar="ğŸ¤–"):
				st.markdown(content)


# Main chat interface - ChatGPT style (no columns, full width centered)
st.markdown("## ğŸ¤– Neo4j Knowledge Agent")
st.caption("Ask me anything about the knowledge graph")

# Show info about embeddings on first visit
if "shown_embeddings_info" not in st.session_state:
	with st.info("â„¹ï¸ **Using free HuggingFace embeddings** - First query may take ~30s to download the model (one-time). Subsequent queries will be fast!"):
		pass
	st.session_state.shown_embeddings_info = True

# Render conversation history
render_messages(st.session_state.threads[st.session_state.current_thread]["messages"])

# Chat input at the bottom (ChatGPT style)
user_input = st.chat_input("à¸ªà¹ˆà¸‡à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸‚à¸­à¸‡à¸„à¸¸à¸“... (Type your message...)", key="chat_input")

if user_input and user_input.strip():
	# append user message
	tid = st.session_state.current_thread
	msg = {"role": "user", "content": user_input.strip(), "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
	st.session_state.threads[tid]["messages"].append(msg)
	
	# Display user message immediately
	with st.chat_message("user", avatar="ğŸ‘¤"):
		st.markdown(user_input.strip())

	# query neo4j for context and call model
	with st.chat_message("assistant", avatar="ğŸ¤–"):
		with st.spinner("à¸à¸³à¸¥à¸±à¸‡à¸„à¹‰à¸™à¸«à¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥... (Searching knowledge graph...)"):
			# Initialize variables at the start
			ctx = ""
			nodes = []
			
			# Use relationship-aware vector search (gets nodes + their connections via WORKS_AS, etc.)
			if VECTOR_SEARCH_AVAILABLE and query_with_relationships is not None:
				try:
					st.caption(f"ğŸ” Searching with relationships (Person â†’ Position, Agency, etc.)...")
					results = query_with_relationships(
						user_input,
						top_k_per_index=3,  # Get 3 results from each index
					)
					
					# results is List[dict] with __relationships__ included
					if results and len(results) > 0:
						st.caption(f"âœ… Found {len(results)} nodes with relationship data")
						
						# Build context from the node properties AND relationships
						ctx = build_context(results)
						
						if ctx.strip():
							st.caption(f"âœ… à¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ {len(results)} à¸£à¸²à¸¢à¸à¸²à¸£à¸à¸£à¹‰à¸­à¸¡à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œ (Found {len(results)} nodes with relationships)")
						else:
							st.warning(f"âš ï¸ Vector search found nodes but context is empty. Trying Cypher fallback...")
							driver = get_driver()
							nodes = search_nodes(driver, user_input)
							ctx = build_context(nodes)
							if nodes:
								st.caption(f"âœ… à¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ {len(nodes)} à¸£à¸²à¸¢à¸à¸²à¸£à¸ˆà¸²à¸ Cypher (Found {len(nodes)} nodes)")
					else:
						st.warning(f"âš ï¸ Vector search returned no results. Trying Cypher fallback...")
						driver = get_driver()
						nodes = search_nodes(driver, user_input)
						ctx = build_context(nodes)
						if nodes:
							st.caption(f"âœ… à¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ {len(nodes)} à¸£à¸²à¸¢à¸à¸²à¸£à¸ˆà¸²à¸ Cypher (Found {len(nodes)} nodes)")
						else:
							st.caption(f"âŒ No results from Cypher search either")
							
				except Exception as e:
					# fall back to simple cypher search if vector retrieval fails
					st.warning(f"âš ï¸ Vector search error: {str(e)[:100]}... Trying Cypher fallback...")
					try:
						driver = get_driver()
						nodes = search_nodes(driver, user_input)
						ctx = build_context(nodes)
						if nodes:
							st.caption(f"âœ… à¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ {len(nodes)} à¸£à¸²à¸¢à¸à¸²à¸£à¸ˆà¸²à¸ Cypher (Found {len(nodes)} nodes)")
					except Exception as e2:
						ctx = ""
						st.error(f"Both vector and Cypher search failed. Vector error: {str(e)[:50]}, Cypher error: {str(e2)[:50]}")
			else:
				# query_vector_rag not available (package or import issue) â€” use cypher search
				try:
					driver = get_driver()
					nodes = search_nodes(driver, user_input)
					ctx = build_context(nodes)
					
					# Debug: show how many nodes were found
					if nodes:
						st.caption(f"âœ… à¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥ {len(nodes)} à¸£à¸²à¸¢à¸à¸²à¸£à¸ˆà¸²à¸ Neo4j (Found {len(nodes)} nodes)")
					else:
						st.caption(f"âš ï¸ à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸à¸±à¸šà¸„à¸³à¸„à¹‰à¸™à¸«à¸² '{user_input}' (No matching nodes found)")
						
				except Exception as e:
					ctx = ""
					st.error(f"âŒ Neo4j error: {e}")

			# Don't use fallback docs if they're irrelevant to the query
			# Only use fallback for demo/development when Neo4j is completely unavailable
			if not ctx and not nodes:
				# Check if we're in a real error state (can't connect) vs just no results
				st.info("ğŸ’¡ à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¹ƒà¸™ Knowledge Graph / No relevant information found in the knowledge graph")
				ctx = ""  # Let the LLM know there's no context
			
			# Show context in expandable section for debugging
			if ctx:
				with st.expander("ğŸ” à¸”à¸¹à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸à¸š (View Retrieved Context)", expanded=False):
					st.code(ctx, language="text")

			# Enhanced comprehensive system prompt for maximum accuracy
			prompt = f"""à¸„à¸¸à¸“à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¸­à¸±à¸ˆà¸‰à¸£à¸´à¸¢à¸°à¸—à¸µà¹ˆà¹€à¸Šà¸µà¹ˆà¸¢à¸§à¸Šà¸²à¸à¸”à¹‰à¸²à¸™à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ Knowledge Graph à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¹€à¸„à¸£à¸·à¸­à¸‚à¹ˆà¸²à¸¢à¸šà¸¸à¸„à¸„à¸¥à¹à¸¥à¸°à¸­à¸‡à¸„à¹Œà¸à¸£
(You are an intelligent assistant specialized in analyzing Knowledge Graph data about social networks and organizations)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ Neo4j Knowledge Graph (Data from Neo4j Knowledge Graph):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{ctx if ctx else "âš ï¸ à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¹‚à¸”à¸¢à¸•à¸£à¸‡à¹ƒà¸™ Knowledge Graph (No directly relevant information found in the Knowledge Graph)"}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â“ à¸„à¸³à¸–à¸²à¸¡à¸‚à¸­à¸‡à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰ (User's Question):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{user_input}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“‹ à¸„à¸³à¹à¸™à¸°à¸™à¸³à¹ƒà¸™à¸à¸²à¸£à¸•à¸­à¸šà¸­à¸¢à¹ˆà¸²à¸‡à¸¥à¸°à¹€à¸­à¸µà¸¢à¸” (Detailed Response Guidelines):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ **à¸«à¸¥à¸±à¸à¸à¸²à¸£à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡ (Core Principles):**

1. **à¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡ (Accuracy)**:
   - à¸•à¸­à¸šà¹‚à¸”à¸¢à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ Context à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ - à¸«à¹‰à¸²à¸¡à¹€à¸”à¸²à¸«à¸£à¸·à¸­à¸ªà¸¡à¸¡à¸•à¸´à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸¡à¸µ
   - à¸–à¹‰à¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ à¹ƒà¸«à¹‰à¸šà¸­à¸à¸ªà¹ˆà¸§à¸™à¸—à¸µà¹ˆà¸£à¸¹à¹‰à¹à¸¥à¸°à¸£à¸°à¸šà¸¸à¸§à¹ˆà¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸”à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸¡à¸µ
   - à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸¥à¸¢ à¹ƒà¸«à¹‰à¸šà¸­à¸à¸•à¸£à¸‡à¹† à¸§à¹ˆà¸² "à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™ Knowledge Graph"

2. **à¸„à¸§à¸²à¸¡à¸Šà¸±à¸”à¹€à¸ˆà¸™ (Clarity)**:
   - à¹€à¸£à¸´à¹ˆà¸¡à¸”à¹‰à¸§à¸¢à¸„à¸³à¸•à¸­à¸šà¸—à¸µà¹ˆà¸•à¸£à¸‡à¸›à¸£à¸°à¹€à¸”à¹‡à¸™à¸—à¸±à¸™à¸—à¸µ (à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸šà¸­à¸à¸§à¹ˆà¸² "à¸•à¸²à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥..." à¸«à¸£à¸·à¸­ "à¸ˆà¸²à¸à¸—à¸µà¹ˆà¹„à¸”à¹‰à¸£à¸±à¸š...")
   - à¹ƒà¸Šà¹‰à¸ à¸²à¸©à¸²à¸—à¸µà¹ˆà¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸‡à¹ˆà¸²à¸¢ à¹€à¸›à¹‡à¸™à¸˜à¸£à¸£à¸¡à¸Šà¸²à¸•à¸´ à¹„à¸¡à¹ˆà¹€à¸›à¹‡à¸™à¸—à¸²à¸‡à¸à¸²à¸£à¹€à¸à¸´à¸™à¹„à¸›
   - à¸ˆà¸±à¸”à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹ƒà¸«à¹‰à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢ à¹ƒà¸Šà¹‰ bullet points à¸«à¸£à¸·à¸­ numbering à¹€à¸¡à¸·à¹ˆà¸­à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸²à¸¢à¸£à¸²à¸¢à¸à¸²à¸£

3. **à¸„à¸§à¸²à¸¡à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ (Completeness)**:
   - à¸£à¸§à¸šà¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”à¸ˆà¸²à¸ Context
   - à¸–à¹‰à¸²à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œ (Relationships) à¹à¸ªà¸”à¸‡à¹ƒà¸«à¹‰à¹€à¸«à¹‡à¸™à¸à¸²à¸£à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¹‚à¸¢à¸‡
   - à¸–à¹‰à¸²à¸¡à¸µà¸«à¸¥à¸²à¸¢à¸„à¸³à¸•à¸­à¸šà¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™à¹„à¸›à¹„à¸”à¹‰ à¹ƒà¸«à¹‰à¸£à¸°à¸šà¸¸à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”

4. **à¸ à¸²à¸©à¸² (Language)**:
   - à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸–à¹‰à¸²à¸„à¸³à¸–à¸²à¸¡à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢
   - à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¸­à¸±à¸‡à¸à¸¤à¸©à¸–à¹‰à¸²à¸„à¸³à¸–à¸²à¸¡à¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¸­à¸±à¸‡à¸à¸¤à¸©
   - à¹ƒà¸Šà¹‰à¸„à¸³à¸¨à¸±à¸à¸—à¹Œà¹€à¸‰à¸à¸²à¸°à¸—à¸µà¹ˆà¸›à¸£à¸²à¸à¸à¹ƒà¸™ Context (à¹€à¸Šà¹ˆà¸™ à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡, à¸«à¸™à¹ˆà¸§à¸¢à¸‡à¸²à¸™)

ğŸ” **à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸‰à¸à¸²à¸°à¸—à¸²à¸‡ (Specific Data Handling):**

**à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸–à¸²à¸¡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸šà¸¸à¸„à¸„à¸¥ (Person Questions):**
- à¸£à¸°à¸šà¸¸à¸Šà¸·à¹ˆà¸­-à¸™à¸²à¸¡à¸ªà¸à¸¸à¸¥à¹€à¸•à¹‡à¸¡ (à¸–à¹‰à¸²à¸¡à¸µ)
- à¸£à¸°à¸šà¸¸à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡ (Position) à¸ˆà¸²à¸ Relationship "WORKS_AS" à¸«à¸£à¸·à¸­ property "à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡"
- à¸£à¸°à¸šà¸¸à¸«à¸™à¹ˆà¸§à¸¢à¸‡à¸²à¸™ (Agency) à¸ˆà¸²à¸ Relationship "WORKS_AT" à¸«à¸£à¸·à¸­ property "à¸«à¸™à¹ˆà¸§à¸¢à¸‡à¸²à¸™"
- à¸£à¸°à¸šà¸¸à¸à¸£à¸°à¸—à¸£à¸§à¸‡ (Ministry) à¸–à¹‰à¸²à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥
- à¸£à¸°à¸šà¸¸à¸Šà¸·à¹ˆà¸­à¹€à¸¥à¹ˆà¸™ (Nickname) à¸–à¹‰à¸²à¸¡à¸µà¹ƒà¸™ property "à¸Šà¸·à¹ˆà¸­à¹€à¸¥à¹ˆà¸™"
- à¹à¸ªà¸”à¸‡ Relationships à¸­à¸·à¹ˆà¸™à¹† à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡ (Connect by, Associate, Remark)

**à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸–à¸²à¸¡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸•à¸³à¹à¸«à¸™à¹ˆà¸‡ (Position Questions):**
- à¸£à¸°à¸šà¸¸à¸Šà¸·à¹ˆà¸­à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸­à¸¢à¹ˆà¸²à¸‡à¸Šà¸±à¸”à¹€à¸ˆà¸™
- à¸£à¸°à¸šà¸¸à¸šà¸¸à¸„à¸„à¸¥à¸—à¸µà¹ˆà¸”à¸³à¸£à¸‡à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸™à¸µà¹‰ (à¸–à¹‰à¸²à¸¡à¸µ)
- à¸£à¸°à¸šà¸¸à¸«à¸™à¹ˆà¸§à¸¢à¸‡à¸²à¸™/à¸à¸£à¸°à¸—à¸£à¸§à¸‡à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡ (à¸–à¹‰à¸²à¸¡à¸µ)

**à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸–à¸²à¸¡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸«à¸™à¹ˆà¸§à¸¢à¸‡à¸²à¸™/à¸à¸£à¸°à¸—à¸£à¸§à¸‡ (Organization Questions):**
- à¸£à¸°à¸šà¸¸à¸Šà¸·à¹ˆà¸­à¸«à¸™à¹ˆà¸§à¸¢à¸‡à¸²à¸™/à¸à¸£à¸°à¸—à¸£à¸§à¸‡à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡
- à¸£à¸°à¸šà¸¸à¸šà¸¸à¸„à¸„à¸¥à¸—à¸µà¹ˆà¸—à¸³à¸‡à¸²à¸™à¹ƒà¸™à¸«à¸™à¹ˆà¸§à¸¢à¸‡à¸²à¸™à¸™à¸µà¹‰
- à¸£à¸°à¸šà¸¸à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œ (à¹€à¸Šà¹ˆà¸™ à¸«à¸™à¹ˆà¸§à¸¢à¸‡à¸²à¸™ UNDER à¸à¸£à¸°à¸—à¸£à¸§à¸‡)

**à¸ªà¸³à¸«à¸£à¸±à¸šà¸„à¸³à¸–à¸²à¸¡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œ (Relationship Questions):**
- à¸­à¸˜à¸´à¸šà¸²à¸¢à¸›à¸£à¸°à¹€à¸ à¸—à¸‚à¸­à¸‡à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œ (WORKS_AS, WORKS_AT, MEMBER_OF, Connect by, etc.)
- à¸£à¸°à¸šà¸¸à¸—à¸´à¸¨à¸—à¸²à¸‡ (â†’ à¸«à¸£à¸·à¸­ â†)
- à¹à¸ªà¸”à¸‡à¸šà¸¸à¸„à¸„à¸¥à¸«à¸£à¸·à¸­à¸­à¸‡à¸„à¹Œà¸à¸£à¸—à¸µà¹ˆà¹€à¸Šà¸·à¹ˆà¸­à¸¡à¹‚à¸¢à¸‡à¸à¸±à¸™

ğŸ“ **à¸£à¸¹à¸›à¹à¸šà¸šà¸„à¸³à¸•à¸­à¸šà¸—à¸µà¹ˆà¹à¸™à¸°à¸™à¸³ (Recommended Answer Format):**

**à¸–à¹‰à¸²à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸„à¸£à¸šà¸–à¹‰à¸§à¸™:**
```
[à¸„à¸³à¸•à¸­à¸šà¹‚à¸”à¸¢à¸•à¸£à¸‡ 1-2 à¸›à¸£à¸°à¹‚à¸¢à¸„]

à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡:
â€¢ [à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸„à¸±à¸à¸‚à¹‰à¸­à¸—à¸µà¹ˆ 1]
â€¢ [à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸„à¸±à¸à¸‚à¹‰à¸­à¸—à¸µà¹ˆ 2]
â€¢ [à¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡ (à¸–à¹‰à¸²à¸¡à¸µ)]

[à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸ªà¸£à¸´à¸¡à¸«à¸£à¸·à¸­à¸šà¸£à¸´à¸šà¸— (à¸–à¹‰à¸²à¸¡à¸µ)]
```

**à¸–à¹‰à¸²à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ:**
```
à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¡à¸µà¹ƒà¸™ Knowledge Graph:
[à¸£à¸°à¸šà¸¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¡à¸µ]

à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£à¸à¹‡à¸•à¸²à¸¡ à¸¢à¸±à¸‡à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸š:
â€¢ [à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸‚à¸²à¸”à¸«à¸²à¸¢à¹„à¸›]

à¸„à¸¸à¸“à¸ªà¸²à¸¡à¸²à¸£à¸–à¸¥à¸­à¸‡à¸–à¸²à¸¡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸š: [à¹à¸™à¸°à¸™à¸³à¸„à¸³à¸–à¸²à¸¡à¸—à¸²à¸‡à¹€à¸¥à¸·à¸­à¸]
```

**à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸¥à¸¢:**
```
à¸‚à¸­à¸­à¸ à¸±à¸¢à¸„à¹ˆà¸°/à¸„à¸£à¸±à¸š à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸š "[à¸„à¸³à¸„à¹‰à¸™à¸«à¸²]" à¹ƒà¸™ Knowledge Graph à¹ƒà¸™à¸‚à¸“à¸°à¸™à¸µà¹‰

à¸„à¸¸à¸“à¸­à¸²à¸ˆà¸¥à¸­à¸‡à¸„à¹‰à¸™à¸«à¸²:
â€¢ [à¸„à¸³à¸–à¸²à¸¡à¸—à¸²à¸‡à¹€à¸¥à¸·à¸­à¸à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡ 1]
â€¢ [à¸„à¸³à¸–à¸²à¸¡à¸—à¸²à¸‡à¹€à¸¥à¸·à¸­à¸à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡ 2]
â€¢ [à¸„à¸³à¸–à¸²à¸¡à¸—à¸²à¸‡à¹€à¸¥à¸·à¸­à¸à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡ 3]
```

âš ï¸ **à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸«à¸¥à¸µà¸à¹€à¸¥à¸µà¹ˆà¸¢à¸‡ (What to Avoid):**
- âŒ à¸«à¹‰à¸²à¸¡à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¸—à¸±à¹ˆà¸§à¹„à¸›à¸‚à¸­à¸‡ LLM (à¹€à¸Šà¹ˆà¸™ à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸‚à¹ˆà¸²à¸§à¸«à¸£à¸·à¸­à¸­à¸´à¸™à¹€à¸—à¸­à¸£à¹Œà¹€à¸™à¹‡à¸•)
- âŒ à¸«à¹‰à¸²à¸¡à¹€à¸”à¸²à¸«à¸£à¸·à¸­à¸ªà¸±à¸™à¸™à¸´à¸©à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸¡à¸µà¹ƒà¸™ Context
- âŒ à¸«à¹‰à¸²à¸¡à¸šà¸­à¸à¸§à¹ˆà¸² "à¸‰à¸±à¸™à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸Šà¹ˆà¸§à¸¢à¹„à¸”à¹‰" - à¹à¸—à¸™à¸—à¸µà¹ˆà¸”à¹‰à¸§à¸¢ "à¹„à¸¡à¹ˆà¸à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥" à¹à¸¥à¸°à¹€à¸ªà¸™à¸­à¸—à¸²à¸‡à¹€à¸¥à¸·à¸­à¸
- âŒ à¸«à¹‰à¸²à¸¡à¹€à¸£à¸´à¹ˆà¸¡à¸›à¸£à¸°à¹‚à¸¢à¸„à¸”à¹‰à¸§à¸¢ "à¸•à¸²à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹„à¸”à¹‰à¸£à¸±à¸š..." à¸«à¸£à¸·à¸­ "à¸ˆà¸²à¸ Context..." (à¹€à¸£à¸´à¹ˆà¸¡à¸•à¸­à¸šà¹€à¸¥à¸¢)
- âŒ à¸«à¹‰à¸²à¸¡à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸²à¸‡à¹€à¸—à¸„à¸™à¸´à¸„ (Node labels, property names) à¹ƒà¸«à¹‰à¸à¸±à¸šà¸œà¸¹à¹‰à¹ƒà¸Šà¹‰

âœ¨ **à¹€à¸„à¸¥à¹‡à¸”à¸¥à¸±à¸šà¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡ (Additional Tips):**
- à¹ƒà¸Šà¹‰à¸•à¸±à¸§à¹€à¸¥à¸‚à¸«à¸£à¸·à¸­ bullet points à¹€à¸¡à¸·à¹ˆà¸­à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸¡à¸²à¸à¸à¸§à¹ˆà¸² 2 à¸£à¸²à¸¢à¸à¸²à¸£
- à¹€à¸™à¹‰à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸ªà¸³à¸„à¸±à¸à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¸à¹ˆà¸­à¸™
- à¸–à¹‰à¸²à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸—à¸µà¹ˆà¸™à¹ˆà¸²à¸ªà¸™à¹ƒà¸ˆ à¹ƒà¸«à¹‰à¸à¸¥à¹ˆà¸²à¸§à¸–à¸¶à¸‡
- à¸›à¸´à¸”à¸—à¹‰à¸²à¸¢à¸”à¹‰à¸§à¸¢à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸ªà¸£à¸´à¸¡à¸«à¸£à¸·à¸­à¸„à¸³à¹à¸™à¸°à¸™à¸³ (à¸–à¹‰à¸²à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ’¬ à¸„à¸³à¸•à¸­à¸šà¸‚à¸­à¸‡à¸„à¸¸à¸“ (Your Response):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

"""
			
			answer = ask_openrouter_requests(prompt, max_tokens=1024)
			st.markdown(answer)
	
	resp = {"role": "assistant", "content": answer, "time": datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
	st.session_state.threads[tid]["messages"].append(resp)
	st.rerun()

